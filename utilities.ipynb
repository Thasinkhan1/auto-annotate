{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 22:29:36.909937: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-17 22:29:36.998873: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-17 22:29:37.622059: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-17 22:29:37.625335: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-17 22:29:39.044066: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import kaggle as kg\n",
    "import os\n",
    "import cv2\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import ast\n",
    "from keras.models import Model\n",
    "from keras.applications import VGG16\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Conv2D\n",
    "from xml.etree import ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchor_boxes(image_size,grids_size,aspect_ratios):\n",
    "\n",
    "    image_width, image_height, _ = image_size\n",
    "\n",
    "    grid_width = image_width//grids_size[0]\n",
    "    grid_height = image_height//grids_size[1]\n",
    "\n",
    "    grid_center_x_start = grid_width//2\n",
    "    grid_center_x_end = int((grids_size[0] - 0.5)*grid_width) \n",
    "\n",
    "    grid_center_x = np.linspace(grid_center_x_start,grid_center_x_end,grids_size[0])\n",
    "\n",
    "    grid_center_y_start = grid_height//2\n",
    "    grid_center_y_end = int((grids_size[1] - 0.5)*grid_height)\n",
    "\n",
    "    grid_center_y = np.linspace(grid_center_y_start,grid_center_y_end,grids_size[1])\n",
    "\n",
    "    grid_center_x_mesh, grid_center_y_mesh = np.meshgrid(grid_center_x,grid_center_y)\n",
    "\n",
    "    grid_center_x_mesh = np.expand_dims(grid_center_x_mesh,-1)\n",
    "    grid_center_y_mesh = np.expand_dims(grid_center_y_mesh,-1)\n",
    "\n",
    "    anchor_boxes_no = len(aspect_ratios)\n",
    "\n",
    "    anchor_boxes_tensor = np.zeros((grids_size[0],grids_size[1],anchor_boxes_no,4))\n",
    "\n",
    "    anchor_boxes_tensor[...,0] = np.tile(grid_center_x_mesh,(1,1,anchor_boxes_no))\n",
    "    anchor_boxes_tensor[...,1] = np.tile(grid_center_y_mesh,(1,1,anchor_boxes_no))\n",
    "\n",
    "    anchor_box_width_height = list()\n",
    "\n",
    "    for aspect_ratio in aspect_ratios:\n",
    "\n",
    "        anchor_box_width_height.append((grid_width*np.sqrt(aspect_ratio),\n",
    "                                        grid_height/np.sqrt(aspect_ratio)))\n",
    "        \n",
    "    anchor_box_width_height = np.array(anchor_box_width_height)\n",
    "\n",
    "    anchor_boxes_tensor[...,2] = anchor_box_width_height[:,0]\n",
    "    anchor_boxes_tensor[...,3] = anchor_box_width_height[:,1]\n",
    "\n",
    "    return anchor_boxes_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid2minmax(anchor_boxes_centroid_tensor):\n",
    "\n",
    "    anchor_boxes_minmax_tensor = np.copy(anchor_boxes_centroid_tensor)\n",
    "\n",
    "    anchor_boxes_minmax_tensor[...,0] = anchor_boxes_minmax_tensor[...,0] - (anchor_boxes_minmax_tensor[...,2]//2)\n",
    "    anchor_boxes_minmax_tensor[...,1] = anchor_boxes_minmax_tensor[...,1] - (anchor_boxes_minmax_tensor[...,3]//2)\n",
    "    anchor_boxes_minmax_tensor[...,2] = anchor_boxes_minmax_tensor[...,0] + (anchor_boxes_minmax_tensor[...,2]//2)\n",
    "    anchor_boxes_minmax_tensor[...,3] = anchor_boxes_minmax_tensor[...,1] + (anchor_boxes_minmax_tensor[...,3]//2)\n",
    "\n",
    "    return anchor_boxes_minmax_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_IoU(anchor_boxes_minmax_tensor,image_gt_bbox_coords):\n",
    "\n",
    "    image_gt_bbox_centroid_coords = np.array(image_gt_bbox_coords)\n",
    "    image_gt_bbox_centroid_coords[:,0] = image_gt_bbox_centroid_coords[:,0] +\\\n",
    "                                         (image_gt_bbox_centroid_coords[:,2] - image_gt_bbox_centroid_coords[:,0])//2\n",
    "    image_gt_bbox_centroid_coords[:,1] = image_gt_bbox_centroid_coords[:,1] +\\\n",
    "                                         (image_gt_bbox_centroid_coords[:,3] - image_gt_bbox_centroid_coords[:,1])//2\n",
    "    image_gt_bbox_centroid_coords[:,2] = (image_gt_bbox_centroid_coords[:,2] - image_gt_bbox_centroid_coords[:,0])\n",
    "    image_gt_bbox_centroid_coords[:,3] = (image_gt_bbox_centroid_coords[:,3] - image_gt_bbox_centroid_coords[:,1]) \n",
    "    \n",
    "    IoU_tensor = np.zeros((len(image_gt_bbox_coords),anchor_boxes_minmax_tensor.shape[0],anchor_boxes_minmax_tensor.shape[1],\n",
    "                    anchor_boxes_minmax_tensor.shape[2]))\n",
    "    bbox_present_idxes = [[]]*len(image_gt_bbox_coords) \n",
    "    IoU_thresh = 0.25\n",
    "\n",
    "    for i in range(len(image_gt_bbox_coords)):\n",
    "\n",
    "        for j in range(anchor_boxes_minmax_tensor.shape[2]):\n",
    "            \"\"\"\n",
    "            centroid_x_condition_anchor_boxes = ((image_gt_bbox_centroid_coords[i,0] > anchor_boxes_minmax_tensor[:,:,j,0]) & \n",
    "                                               (image_gt_bbox_centroid_coords[i,0] < anchor_boxes_minmax_tensor[:,:,j,2]))\n",
    "            centroid_y_condition_anchor_boxes = ((image_gt_bbox_centroid_coords[i,1] > anchor_boxes_minmax_tensor[:,:,j,1]) & \n",
    "                                               (image_gt_bbox_centroid_coords[i,1] < anchor_boxes_minmax_tensor[:,:,j,3]))\n",
    "            grid_cells_idxes = np.argwhere(centroid_x_condition_anchor_boxes & centroid_y_condition_anchor_boxes)\n",
    "            bbox_present_idxes[i].append(grid_cells_idxes)\n",
    "            \"\"\"\n",
    "\n",
    "            xmin_intersection = np.maximum(image_gt_bbox_coords[i][0],anchor_boxes_minmax_tensor[:,:,j,0])\n",
    "            ymin_intersection = np.maximum(image_gt_bbox_coords[i][1],anchor_boxes_minmax_tensor[:,:,j,1])\n",
    "\n",
    "            xmax_intersection = np.minimum(image_gt_bbox_coords[i][2],anchor_boxes_minmax_tensor[:,:,j,2])\n",
    "            ymax_intersection = np.minimum(image_gt_bbox_coords[i][3],anchor_boxes_minmax_tensor[:,:,j,3])\n",
    "\n",
    "            intersection_width = np.maximum(0,(xmax_intersection - xmin_intersection))\n",
    "            intersection_height = np.maximum(0,(ymax_intersection - ymin_intersection))\n",
    "\n",
    "            intersection_area = intersection_width * intersection_height\n",
    "\n",
    "            image_gt_bbox_area = image_gt_bbox_centroid_coords[i,2] * image_gt_bbox_centroid_coords[i,3]\n",
    "            anchor_boxes_width = (anchor_boxes_minmax_tensor[:,:,j,2] - anchor_boxes_minmax_tensor[:,:,j,0])\n",
    "            anchor_boxes_height = (anchor_boxes_minmax_tensor[:,:,j,3] - anchor_boxes_minmax_tensor[:,:,j,1])\n",
    "\n",
    "            union_area = ((anchor_boxes_width * anchor_boxes_height) + image_gt_bbox_area) - intersection_area\n",
    "\n",
    "            IoU_tensor[i,:,:,j] = intersection_area/union_area\n",
    "            bbox_present_idxes[i].append(np.argwhere(IoU_tensor[i,:,:,j] > 0))\n",
    "\n",
    "    IoU_tensor_reduced = np.max(IoU_tensor,axis=0)\n",
    "    anchor_boxes_gt_mask = np.float64(IoU_tensor_reduced > IoU_thresh)\n",
    "\n",
    "    return image_gt_bbox_centroid_coords, anchor_boxes_gt_mask, bbox_present_idxes, IoU_tensor_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_bbox_coords(image_size,amchor_boxes_gt_mask,bbox_present_idxes,image_gt_bbox_centroid_coords,anchor_boxes_minmax_tensor):\n",
    "\n",
    "    image_width, image_height, _ = image_size\n",
    "    normalized_image_gt_bbox_coords = np.zeros_like(anchor_boxes_minmax_tensor)\n",
    "\n",
    "    for i in range(len(image_gt_bbox_centroid_coords)):\n",
    "    \n",
    "        for j in range(anchor_boxes_minmax_tensor.shape[2]):\n",
    "\n",
    "            idx = bbox_present_idxes[i][j]\n",
    "\n",
    "            normalized_image_gt_bbox_coords[idx[:,0],idx[:,1],j,0] = image_gt_bbox_centroid_coords[i][0]/anchor_boxes_minmax_tensor[idx[:,0],idx[:,1],j,2]\n",
    "            normalized_image_gt_bbox_coords[idx[:,0],idx[:,1],j,1] = image_gt_bbox_centroid_coords[i][1]/anchor_boxes_minmax_tensor[idx[:,0],idx[:,1],j,3]\n",
    "            normalized_image_gt_bbox_coords[idx[:,0],idx[:,1],j,2] = image_gt_bbox_centroid_coords[i][2]/image_width\n",
    "            normalized_image_gt_bbox_coords[idx[:,0],idx[:,1],j,3] = image_gt_bbox_centroid_coords[i][3]/image_height\n",
    "\n",
    "    return normalized_image_gt_bbox_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gt_labels_tensor(normalized_image_gt_bbox_coords, IoU_tensor, bbox_present_idxes, image_cls_labels, num_classes):\n",
    "\n",
    "    cls_probabilities_tensor = np.zeros((normalized_image_gt_bbox_coords.shape[0],normalized_image_gt_bbox_coords.shape[1],num_classes))\n",
    "\n",
    "    for i in range(len(bbox_present_idxes)):\n",
    "        idx_0 = bbox_present_idxes[i][0]\n",
    "        idx_1 = bbox_present_idxes[i][1]\n",
    "        cls_probabilities_tensor[idx_0[:,0],idx_0[:,1],:] = np.eye(num_classes,num_classes)[image_cls_labels[i]]\n",
    "        cls_probabilities_tensor[idx_1[:,0],idx_1[:,1],:] = np.eye(num_classes,num_classes)[image_cls_labels[i]]\n",
    "\n",
    "    gt_labels_tensor = np.copy(normalized_image_gt_bbox_coords)\n",
    "    confidence_scores = np.expand_dims(IoU_tensor,-1)\n",
    "    gt_labels_tensor = np.concatenate((gt_labels_tensor,confidence_scores),axis=3)\n",
    "    gt_labels_tensor = gt_labels_tensor.reshape(gt_labels_tensor.shape[0],gt_labels_tensor.shape[1],gt_labels_tensor.shape[2]*gt_labels_tensor.shape[3])\n",
    "    gt_labels_tensor = np.concatenate((gt_labels_tensor,cls_probabilities_tensor),axis=2)\n",
    "    \n",
    "    return gt_labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_cnn():\n",
    "\n",
    "    vgg16 = VGG16(include_top=False,input_shape=(640,480,3),weights=\"imagenet\",pooling=None)\n",
    "    vgg16.trainable = False\n",
    "    input_to_vgg16 = vgg16.input\n",
    "    vgg16_output = Conv2D(filters=90,kernel_size=(14,9))(vgg16.layers[-1].output)\n",
    "\n",
    "    return Model(inputs=[input_to_vgg16],outputs=[vgg16_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 640, 480, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 640, 480, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 640, 480, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 320, 240, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 320, 240, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 320, 240, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 160, 120, 128)     0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 160, 120, 256)     295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 160, 120, 256)     590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 160, 120, 256)     590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 80, 60, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 80, 60, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 80, 60, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 80, 60, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 40, 30, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 40, 30, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 40, 30, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 40, 30, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 20, 15, 512)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 7, 7, 90)          5806170   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20520858 (78.28 MB)\n",
      "Trainable params: 5806170 (22.15 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = multiclass_cnn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_df(imgs_base_path,annotations_base_path):\n",
    "\n",
    "    img_complete_paths = list()\n",
    "    img_class_labels = list()\n",
    "    img_gt_bbox_coords = list()\n",
    "\n",
    "    for single_img_complete_path in pathlib.Path(imgs_base_path).glob(\"*\"):\n",
    "\n",
    "        img_path = str(single_img_complete_path)\n",
    "        img_label_path = os.path.join(annotations_base_path,str(single_img_complete_path).split(\"/\")[-1].split(\".\")[0]+\".xml\")\n",
    "\n",
    "        class_gt_labels_list = list()\n",
    "        gt_bbox_coords_list = list()\n",
    "\n",
    "        tree = ET.parse(img_label_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        for member in root.findall(\"object\"):\n",
    "            \"\"\"\n",
    "            for child in member:\n",
    "\n",
    "                if child.tag == \"name\":\n",
    "                    class_gt_labels_list.append(child.text)\n",
    "\n",
    "                if child.tag == \"bndbox\":\n",
    "                    xmin = float(child[0].text)\n",
    "                    ymin = float(child[1].text)\n",
    "                    xmax = float(child[2].text)\n",
    "                    ymax = float(child[3].text)\n",
    "            \"\"\"\n",
    "            class_gt_labels_list.append(member.find(\"name\").text)\n",
    "            xmin = float(member.find(\"bndbox/xmin\").text)\n",
    "            ymin = float(member.find(\"bndbox/ymin\").text)\n",
    "            xmax = float(member.find(\"bndbox/xmax\").text)\n",
    "            ymax = float(member.find(\"bndbox/ymax\").text)\n",
    "            \n",
    "            bbox_width = xmax - xmin\n",
    "            bbox_height = ymax - ymin\n",
    "            \n",
    "\n",
    "            gt_bbox_coords_list.append([xmin,ymin,bbox_width,bbox_height])\n",
    "\n",
    "        img_complete_paths.append(str(single_img_complete_path))\n",
    "        img_class_labels.append(class_gt_labels_list)\n",
    "        img_gt_bbox_coords.append(gt_bbox_coords_list)\n",
    "\n",
    "    return pd.DataFrame(data={\"img_path\":img_complete_paths,\n",
    "                              \"img_gt_class_labels\":img_class_labels,\n",
    "                              \"img_gt_bbox_coords\":img_gt_bbox_coords})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = train_test_df(\"/home/thasin/class-projects/annotate/dataset/VOC2012_train_val/VOC2012_train_val/JPEGImages\",\"/home/thasin/class-projects/annotate/dataset/VOC2012_train_val/VOC2012_train_val/Annotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17125, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = set()\n",
    "\n",
    "for img_labels in data_df.iloc[:,1]:\n",
    "    unique_labels = unique_labels.union(set(img_labels))\n",
    "\n",
    "unique_labels = list(unique_labels)\n",
    "#unique_labels.insert(0,\"background\")\n",
    "\n",
    "labels2idx = dict(zip(unique_labels,range(len(unique_labels))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels2idx_mapping(img_labels):\n",
    "    \n",
    "     return list(map(lambda x: labels2idx[x],img_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.iloc[:,1] = data_df.iloc[:,1].apply(labels2idx_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[\"img_gt_class_labels\"] = data_df[\"img_gt_class_labels\"].apply(json.dumps)\n",
    "data_df[\"img_gt_bbox_coords\"] = data_df[\"img_gt_bbox_coords\"].apply(json.dumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = data_df.iloc[0:15000,:]\n",
    "cv_data = data_df.iloc[15000:,]\n",
    "\n",
    "training_data.to_csv(\"./training_data.csv\",index=False)\n",
    "cv_data.to_csv(\"./cv_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"training_data.csv\")\n",
    "training_data[\"img_gt_class_labels\"] = training_data[\"img_gt_class_labels\"].apply(ast.literal_eval)\n",
    "training_data[\"img_gt_bbox_coords\"] = training_data[\"img_gt_bbox_coords\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 500, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imread(training_data.iloc[0,0]).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngt_bboxes_mask,iou_tensor = compute_IoU(anchor_boxes_tensor,training_data.iloc[0,2])\\n#normalized_gt_bbox_coords = normalize_bbox_coords((640,480,3),training_data.iloc[0,2],gt_bboxes_mask,anchor_boxes_tensor)\\n#gt_labels_tensor = create_gt_labels_tensor(normalized_gt_bbox_coords,iou_tensor,gt_bboxes_mask,training_data.iloc[0,1],\\n                                           20)'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_boxes_tensor = anchor_boxes((640,480,3),(7,7),(1/2,2))\n",
    "anchor_boxes_minmax_tensor = centroid2minmax(anchor_boxes_tensor)\n",
    "\"\"\"\n",
    "gt_bboxes_mask,iou_tensor = compute_IoU(anchor_boxes_tensor,training_data.iloc[0,2])\n",
    "#normalized_gt_bbox_coords = normalize_bbox_coords((640,480,3),training_data.iloc[0,2],gt_bboxes_mask,anchor_boxes_tensor)\n",
    "#gt_labels_tensor = create_gt_labels_tensor(normalized_gt_bbox_coords,iou_tensor,gt_bboxes_mask,training_data.iloc[0,1],\n",
    "                                           20)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_data_generator(df,mb_size):\n",
    "\n",
    "    for i in range(df.shape[0]//mb_size):\n",
    "\n",
    "        X_train_mb = list()\n",
    "        Y_train_mb = list()\n",
    "        GT_mask_train_mb = list()\n",
    "\n",
    "        for j in range(0,mb_size):\n",
    "\n",
    "            df_mb = df.iloc[(i*mb_size)+j]\n",
    "            img_path = df_mb[\"img_path\"]\n",
    "\n",
    "            X_train_mb.append(cv2.resize(plt.imread(img_path),(640,480)))\n",
    "\n",
    "            gt_bboxes_mask, iou_tensor = compute_IoU(anchor_boxes_tensor,df_mb[\"img_gt_bbox_coords\"])\n",
    "            normalized_img_gt_bbox_coords = normalize_bbox_coords((640,480,3),df_mb[\"img_gt_bbox_coords\"],\n",
    "                                                                  gt_bboxes_mask,anchor_boxes_tensor)\n",
    "            Y_train, final_gt_bboxes_mask = create_gt_labels_tensor(normalized_img_gt_bbox_coords,iou_tensor,\n",
    "                                                                    gt_bboxes_mask,df_mb[\"img_gt_class_labels\"],20)\n",
    "            \n",
    "            Y_train_mb.append(Y_train)\n",
    "            GT_mask_train_mb.append(final_gt_bboxes_mask)\n",
    "            \n",
    "        yield np.array(X_train_mb), np.array(Y_train_mb), np.array(GT_mask_train_mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_generator = custom_data_generator(training_data,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_fn(Y_true_mb,Y_pred_mb,GT_mask_train_mb,lambda_coord,lambda_noobj):\n",
    "\n",
    "    squared_error = (Y_true_mb - Y_pred_mb)**2\n",
    "\n",
    "    \"\"\"\n",
    "    squared_error_with_mask = GT_mask_train_mb * squared_error\n",
    "    squared_error_with_neg_mask = (1.0 - GT_mask_train_mb) * squared_error\n",
    "    \"\"\"\n",
    "\n",
    "    cx_cy_squared_error_tensor = np.concatenate((GT_mask_train_mb*squared_error[:,:,:,0:2],\n",
    "                                                 GT_mask_train_mb*squared_error[:,:,:,5:7]),axis=0)\n",
    "    \n",
    "    sqrt_squared_error = (np.sqrt(Y_true_mb) - np.sqrt(Y_pred_mb))**2\n",
    "\n",
    "    #sqrt_squared_error_with_mask = GT_mask_train_mb * sqrt_squared_error\n",
    "    \n",
    "    wh_sqrt_squared_error_tensor = np.concatenate((GT_mask_train_mb*sqrt_squared_error[:,:,:,2:4],\n",
    "                                                   GT_mask_train_mb*sqrt_squared_error[:,:,:,7:9]),axis=0)\n",
    "    \n",
    "    loss_fn_first_term = lambda_coord*np.sum(cx_cy_squared_error_tensor)\n",
    "    loss_fn_second_term = lambda_coord*np.sum(wh_sqrt_squared_error_tensor)\n",
    "\n",
    "    confidence_score_error_tensor = GT_mask_train_mb*np.concatenate((squared_error[:,:,:,4],\n",
    "                                                                     squared_error[:,:,:,9]),axis=0)\n",
    "    \n",
    "    loss_fn_third_term = np.sum(confidence_score_error_tensor)\n",
    "\n",
    "    confidence_score_noobj_error_tensor = (1.0 - GT_mask_train_mb)*np.concatenate((squared_error[:,:,:,4],\n",
    "                                                                                   squared_error[:,:,:,9]),axis=0)\n",
    "\n",
    "    loss_fn_forth_term = lambda_noobj*np.sum(confidence_score_noobj_error_tensor)\n",
    "\n",
    "    loss_fn_fifth_term = GT_mask_train_mb*np.sum(squared_error[:,:,:,10:])\n",
    "\n",
    "    overall_loss_fn = loss_fn_first_term + loss_fn_second_term + loss_fn_third_term +\\\n",
    "                        loss_fn_forth_term + loss_fn_fifth_term\n",
    "    \n",
    "    return overall_loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def training_step(X_train_mb,Y_true_train_mb,GT_mask_train_mb):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "            \n",
    "        Y_pred_train_mb = model(X_train_mb, training=True)\n",
    "        training_loss = custom_loss_fn(Y_true_train_mb, Y_pred_train_mb,GT_mask_train_mb,5,0.5)\n",
    "\n",
    "    grads = tape.gradient(training_loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "    train_acc_metric.update_state(Y_true_train_mb,Y_pred_train_mb)\n",
    "\n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def testing_forward_pass(X_test_mb,Y_true_test_mb,GT_mask_test_mb):\n",
    "\n",
    "    Y_pred_test_mb = model(X_test_mb,training=False)\n",
    "    testing_loss = custom_loss_fn(Y_true_test_mb,Y_pred_test_mb,GT_mask_test_mb)\n",
    "    test_acc_metric.update_state(Y_true_test_mb,Y_pred_test_mb)\n",
    "\n",
    "    return testing_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "training_data_mb_size = 5\n",
    "testing_data_mb_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "len() of unsized object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      6\u001b[0m     training_data_generator \u001b[38;5;241m=\u001b[39m custom_data_generator(training_data,\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m time_step, (X_train_mb, cv_data,GT_mask_train_mb)\u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(training_data_generator):\n\u001b[1;32m      9\u001b[0m         training_loss \u001b[38;5;241m=\u001b[39m training_step(X_train_mb,cv_data,GT_mask_train_mb)\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (time_step\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[36], line 16\u001b[0m, in \u001b[0;36mcustom_data_generator\u001b[0;34m(df, mb_size)\u001b[0m\n\u001b[1;32m     12\u001b[0m img_path \u001b[38;5;241m=\u001b[39m df_mb[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     14\u001b[0m X_train_mb\u001b[38;5;241m.\u001b[39mappend(cv2\u001b[38;5;241m.\u001b[39mresize(plt\u001b[38;5;241m.\u001b[39mimread(img_path),(\u001b[38;5;241m640\u001b[39m,\u001b[38;5;241m480\u001b[39m)))\n\u001b[0;32m---> 16\u001b[0m gt_bboxes_mask, iou_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_IoU\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor_boxes_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf_mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg_gt_bbox_coords\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m normalized_img_gt_bbox_coords \u001b[38;5;241m=\u001b[39m normalize_bbox_coords((\u001b[38;5;241m640\u001b[39m,\u001b[38;5;241m480\u001b[39m,\u001b[38;5;241m3\u001b[39m),df_mb[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg_gt_bbox_coords\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     18\u001b[0m                                                       gt_bboxes_mask,anchor_boxes_tensor)\n\u001b[1;32m     19\u001b[0m Y_train, final_gt_bboxes_mask \u001b[38;5;241m=\u001b[39m create_gt_labels_tensor(normalized_img_gt_bbox_coords,iou_tensor,\n\u001b[1;32m     20\u001b[0m                                                         gt_bboxes_mask,df_mb[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg_gt_class_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m],\u001b[38;5;241m20\u001b[39m)\n",
      "Cell \u001b[0;32mIn[67], line 4\u001b[0m, in \u001b[0;36mcompute_IoU\u001b[0;34m(anchor_boxes_tensor, image_gt_bbox_coords)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_IoU\u001b[39m(anchor_boxes_tensor,image_gt_bbox_coords):\n\u001b[1;32m      3\u001b[0m     image_gt_bbox_coords \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(image_gt_bbox_coords)\n\u001b[0;32m----> 4\u001b[0m     IoU_tensor \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_gt_bbox_coords\u001b[49m\u001b[43m)\u001b[49m,anchor_boxes_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],anchor_boxes_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],anchor_boxes_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m      5\u001b[0m     anchor_boxes_minmax_tensor \u001b[38;5;241m=\u001b[39m centroid2minmax(anchor_boxes_tensor)\n\u001b[1;32m      7\u001b[0m     gt_bboxes_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(image_gt_bbox_coords),anchor_boxes_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],anchor_boxes_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],anchor_boxes_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))\n",
      "\u001b[0;31mTypeError\u001b[0m: len() of unsized object"
     ]
    }
   ],
   "source": [
    "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "test_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    training_data_generator = custom_data_generator(training_data,5)\n",
    "\n",
    "    for time_step, (X_train_mb, cv_data,GT_mask_train_mb)in enumerate(training_data_generator):\n",
    "        training_loss = training_step(X_train_mb,cv_data,GT_mask_train_mb)\n",
    "\n",
    "        if (time_step+1) % 10 == 0:\n",
    "            print(\"Epoch %d, Time Step %d, Training loss for one mini batch: %.4f\"\n",
    "            % (epoch+1, time_step+1, float(training_loss)))\n",
    "            \n",
    "    training_acc = train_acc_metric.result()    \n",
    "    print(\"Epoch %d, Training Accuracy: %.2f\" % (epoch+1,float(training_acc)))\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    testing_data_generator = custom_data_generator(cv_data,5)\n",
    "\n",
    "    for X_test_mb,GT_mask_test_mb in testing_data_generator:\n",
    "        testing_loss = testing_forward_pass(X_test_mb,cv_data,GT_mask_test_mb)\n",
    "\n",
    "    print(\"\\nEpoch %d, Testing Loss for last mini batch: %.4f\" % (epoch+1,float(testing_loss)))\n",
    "    testing_acc = test_acc_metric.result()\n",
    "    print(\"Epoch %d, Testing Accuracy: %.2f\" % (epoch+1,float(testing_acc)))\n",
    "    test_acc_metric.reset_states()\n",
    "\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
